{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Segmentation and Modeling for CryoET - putting the Cell in Cellular Structural Biology","text":"<p>Segmentation and geometrical modeling for Cryo-ET are powerful processing steps that can be used to  generate better visualizations that capture the 3-dimensional nature of tomograms quantify ultrastructure of cellular features,  and provide supporting geometry for particle localization and subtomogram averaging.</p> <p>Because every cellular tomography project involves a different set of features, studying membranes, filaments, large protein complexes, or phase separation, the tools and techniques used for segmentation and modeling can vary widely. Today, we will cover several different software tools that are used for studying membranes and filaments in cryo-ET. If you are interested in studying these or other aspects of cellular ultrastructure, please reach out to me and I will be happy to help you find the right tools for your specific project, or to collaborate to develop new tools if needed - I am always looking for new projects!</p> <p>The three major tools we will cover today are:</p> <ul> <li>Membrain-Seg - a deep learning-based tool for segmenting membranes in cryo-ET data. This tool is nearly bulletproof for segmenting membranes, and does not require retraining. It is developed by Lorenz Lamm as part a collaboration between Ben Engel and Tingying Ping's research groups, and is part of the teamtomo community software development effort led loosely by Alister Burt.</li> <li>Dragonfly - a commercial software package that is widely used in the cryo-ET community for segmentation and modeling. Matt Swulius has developed a number of workflows for Dragonfly that are used for segmentation and modeling of cellular features. Dragonfly is especially nice for its user-friendly interface for generating training data and training and evaluating models for segmentation. This makes it great for studying your filament of choice, since it is flexible and does not rely on pretrained models.</li> <li>Surface Morphometrics - an open-source toolkit for building high quality triangle mesh models in a fully automated way from segmentations in Cryo-ET, and using those segmentations to quantify local and global membrane ultrastructure. This software was developed by me during my postdoc in Danielle Grotjahn's lab at Scripps Research, and my lab is continuing to develop new methodology within the framework. </li> </ul> <p>We'll also use the following tools for visualization and analysis:</p> <ul> <li>IMOD - a suite of tools for 3D reconstruction and modeling of tomographic data. We will use IMOD for visualization of tomograms and segmentations</li> <li>Meshlab - a powerful open-source tool for processing and editing 3D meshes. We will use Meshlab for manual generation of triangle meshes.</li> <li>Paraview - a powerful open-source tool for visualization and analysis of large datasets. We will use Paraview for visualization of quantifications on meshes.</li> </ul>"},{"location":"morphometrics/","title":"Surface Morphometrics","text":""},{"location":"morphometrics/#quantification-of-membrane-surfaces-segmented-from-cryo-et-or-other-volumetric-imaging","title":"Quantification of Membrane Surfaces Segmented from Cryo-ET or other volumetric imaging.","text":"<p>Surface morphometrics is the toolbox I developed during my postdoc to develop </p>"},{"location":"morphometrics/#setup","title":"Setup:","text":"<ol> <li>Activate your conda environment and move to the morpho_run folder:  <pre><code>conda activate morphometrics\nexport PATH=$PATH:/scratch/segmentation_dataset/surface_morphometrics\ncd /scratch/segmentation_dataset/morpho_run\n</code></pre></li> <li>Edit the <code>config.yml</code> file for our project's needs. I prefer visual studio code for this!<ul> <li>Set the <code>data_folder</code> to the folder containing your label file (<code>/scratch/segmentation_dataset/morpho_run/datadir</code>)</li> <li>Set the <code>output_folder</code> to the folder where you want the output files to be saved (<code>/scratch/segmentation_dataset/morpho_run/workdir</code>)</li> <li>Set the <code>max_triangles</code> to 50,000 to speed up computation - this will reduce the quality of the final surfaces so don't do this when you are running at home!</li> <li>Set the <code>num_cores</code> to 16.</li> <li>Set the </li> </ul> </li> </ol>"},{"location":"morphometrics/#example-data","title":"Example data","text":"<p>There is example data and a config available in the <code>morpho_run</code> folder. This is TE3_labels.mrc, which is the same tomogram you will be processing in the rest of the tutorial. You should check some details about it! You can also compare it to the tomogram itself. <pre><code>module load imod\nheader /scratch/segmentation_dataset/morpho_run/datadir/TE3_labels.mrc\nheader /scratch/segmentation_dataset/TE3_tomo.mrc\n</code></pre></p>"},{"location":"morphometrics/#processing-your-data","title":"Processing your data","text":""},{"location":"morphometrics/#interactive-mesh-generation","title":"Interactive mesh generation","text":"<p>We are going to do semi-interactive mesh generation in meshlab to teach you how the sausage is made, but there is also a fully configurable pipeline (<code>python segmentation_to_meshes.py config.yml</code>) that will do the whole thing for you. 1. Prepare the xyz point cloud files to make new meshes: <code>python xyz2ply.py config.yml</code></p>"},{"location":"morphometrics/#pipelined-steps","title":"Pipelined Steps","text":"<ol> <li>Run pycurv for each surface (normally, this is best run in parallel on a cluster):      <code>python run_pycurv.py config.yml TE3_OMM.surface.vtp</code>. Do this again for IMM (it will take a long time for IMM!)     You may see warnings aobut the curvature, this is normal and you do not need to worry.     We may run into memory constraints - if you do, you can reduce the number of triangles in the surface by setting <code>max_triangles</code> to a lower number in the config file. This will reduce the quality of the final surfaces, but will make the computation faster and lower-memory.</li> <li>Measure intra- and inter-surface distances and orientations (also best to run this one in parallel for each original segmentation): <code>python measure_distances_orientations.py config.yml ${i}.mrc</code></li> <li>Combine the results of the pycurv analysis into aggregate Experiments and generate statistics and plots. This requires some manual coding using the Experiment class and its associated methods in the <code>morphometrics_stats.py</code>. Everything is roughly organized around working with the CSVs in pandas dataframes. Running  <code>morphometrics_stats.py</code> as a script with the config file and a filename will output a pickle file with an assembled \"experiment\" object for all the tomos in the data folder. Reusing a pickle file will make your life way easier if you have dozens of tomograms to work with, but it doesn't save too much time with just the example data...</li> </ol> <p>Just in case you have problems running things fast (I don't have a great sense of how long this will take on these machines), I have provided usable output files for the downstream analysis you might want to try.</p>"},{"location":"morphometrics/#inspecting-results","title":"Inspecting Results","text":""},{"location":"morphometrics/#examples-of-generating-statistics-and-plots","title":"Examples of generating statistics and plots:","text":"<ul> <li><code>python single_file_histogram.py workdir/TE3_labels..csv -n curvedness_vv</code> will generate an area-weighted histogram for a feature of interest in a single tomogram. I am using a variant of this script to respond to reviews asking for more per-tomogram visualizations!</li> <li><code>python single_file_2d.py filename.csv -n1 feature1 -n2 feature2</code> will generate a 2D histogram for 2 features of interest for a single surface.</li> <li><code>mitochondria_statistics.py</code> shows analysis and comparison of multiple experiment objects for different sets of tomograms (grouped by treatment in this case). Every single plot and statistic in the preprint version of the paper gets generated by this script.</li> </ul>"},{"location":"morphometrics/#running-individual-steps-without-pipelining","title":"Running individual steps without pipelining","text":"<p>Individual steps are available as click commands in the terminal, and as functions</p> <ol> <li>Robust Mesh Generation<ol> <li><code>mrc2xyz.py</code> to prepare point clouds from voxel segmentation</li> <li><code>xyz2ply.py</code> to perform screened poisson reconstruction and mask the surface</li> <li><code>ply2vtp.py</code> to convert ply files to vtp files ready for pycurv</li> </ol> </li> <li>Surface Morphology Extraction<ol> <li><code>curvature.py</code> to run pycurv in an organized way on pregenerated surfaces</li> <li><code>intradistance_verticality.py</code> to generate distance metrics and verticality measurements within a surface.</li> <li><code>interdistance_orientation.py</code> to generate distance metrics and orientation measurements between surfaces.</li> <li>Outputs: gt graphs for further analysis, vtp files for paraview visualization, and CSV files for         pandas-based plotting and statistics</li> </ol> </li> <li>Morphometric Quantification - there is no click function for this, as the questions answered depend on the biological system of interest!<ol> <li><code>morphometrics_stats.py</code> is a set of classes and functions to generate graphs and statistics with pandas.</li> <li>Paraview for 3D surface mapping of quantifications.</li> </ol> </li> </ol>"},{"location":"morphometrics/#summary-of-file-types","title":"Summary of File Types:","text":"<ul> <li>Files with.xyz extension are point clouds converted, in nm or angstrom scale. This is a flat text file with <code>X Y Z</code> coordinates in each line.</li> <li>Files with .ply extension are the surface meshes (in a binary format), which will be scaled in nm or angstrom scale, and work in many different softwares, including Meshlab. </li> <li>Files with surface.vtp extension are the same surface meshes in the VTK format.         * The .surface.vtp files are a less cross-compatible format, so you can't use them with as many types of software, but they are able to store all the fun quantifications you'll do!. Paraview or pyvista can load this format. This is the format pycurv reads to build graphs.</li> <li>Files with .gt extension are triangle graph files using the <code>graph-tool</code> python toolkit. These graphs enable rapid neighbor-wise operations such as tensor voting, but are not especially useful for manual inspection.</li> <li>Files with .csv extension are quantification outputs per-triangle. These are the files you'll use to generate statistics and plots.</li> <li>Files with .log extension are log files, mostly from the output of the pycurv run.</li> <li>Quantifications (plots and statistical tests) are output in csv, svg, and png formats. </li> </ul>"}]}